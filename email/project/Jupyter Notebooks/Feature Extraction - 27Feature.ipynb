{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION TO CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pprint\n",
    "from urllib.parse import urlparse\n",
    "import email\n",
    "from IPy import IP\n",
    "import email.header\n",
    "from email.parser import BytesParser, Parser\n",
    "from email.policy import default\n",
    "import csv\n",
    "from collections import Counter\n",
    "from html.parser import HTMLParser\n",
    "from spamassassin_client import SpamAssassin\n",
    "import whois\n",
    "import validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''to remove warnings'''\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGE THE DIRECTORY TO CHANGE TARGET DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locations:\n",
    "- /Datasets/non_phishing\n",
    "- /Datasets/phishing\n",
    "- /Datasets/phishing_bad\n",
    "- /Datasets/non_phishing_bad\n",
    "- /IWSPA-PA Dataset/legit\n",
    "- /IWSPA-PA Dataset/phish\n",
    "- /Test Datasets/PhishingNew\n",
    "- /Test Datasets/Legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''CHANGE THIS'''\n",
    "os.chdir('Datasets/xd')\n",
    "phishing_2016 = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Any thoughts on this Humble Bundle of Python...' - Reddit (noreply@redditmail.com) - 2020-07-02 1043.eml\n",
      "'Help  partial string filtering on pandas dat...' - Reddit (noreply@redditmail.com) - 2020-06-21 1315.eml\n",
      "'I get 2 weeks free AND a magazine, too â€ You do. - 'America's Test Kitchen' (News@email.americastestkitchen.com) - 2020-06-23 1915.eml\n",
      "7-Day Flash Sale- SGD45! - 'the ENTERTAINER' (info@theentertainerme.com) - 2020-07-02 1859.eml\n",
      "Arboros Dragon, Sephirot on Cardfight!! Vanguard Wiki has been edited by HellfireIfrit - FANDOM (community@fandom.com) - 2020-06-23 2103.eml\n",
      "As a beginner in AI, what tool should I focus to learn  Keras, TensorFlow or PyTorch...  - Quora Digest (digest-noreply@quora.com) - 2020-06-20 1446.eml\n",
      "Britain's Future Commando Force - 'Telegraph Editor' (telegrapheditor@email3.telegraph.co.uk) - 2020-06-30 0009.eml\n",
      "Check out this weekâ€™s most read articles - 'The Telegraph' (thetelegraph@email3.telegraph.co.uk) - 2020-06-20 2128.eml\n",
      "Congratulate Yeow Kee Tan for 5 years at... - LinkedIn (notifications-noreply@linkedin.com) - 2020-06-29 0754.eml\n",
      "distortion2 just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-07-02 0503.eml\n",
      "distortion2 just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-07-02 1829.eml\n",
      "distortion2 just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-07-03 0703.eml\n",
      "Eileen Chang posted in Belly Happy by Freshly Picked - 'Facebook' (notification@facebookmail.com) - 2020-06-23 0326.eml\n",
      "Eileen Chang posted in Belly Happy by Freshly Picked - 'Facebook' (notification@facebookmail.com) - 2020-06-27 1858.eml\n",
      "Enjoy clarity on this extraordinary week - 'The Telegraph' (thetelegraph@email3.telegraph.co.uk) - 2020-06-27 2129.eml\n",
      "Enlarge your images without sacrificing quality. Get Gigapixel AI on sale now through 7_7 and enhance...e fine details in your images at any size! - Topaz Labs (news@topazlabs.com) - 2020-06-26 0805.eml\n",
      "Ericsson is looking for  Data Analyst Intern. - LinkedIn (jobs-listings@linkedin.com) - 2020-06-25 0326.eml\n",
      "Ervin, start a conversation with your new connection, Jun Wei - Jun Wei Lim via LinkedIn (invitations@linkedin.com) - 2020-06-20 1143.eml\n",
      "Ervin, thanks for being a valued member - LinkedIn (linkedin@e.linkedin.com) - 2020-07-01 2107.eml\n",
      "Ervin, we found some Spaces for you - Quora (spaces-suggestions-noreply@quora.com) - 2020-07-03 0102.eml\n",
      "Ervin, you have a new suggested connection to review - LinkedIn (messages-noreply@linkedin.com) - 2020-06-22 0310.eml\n",
      "Ervin, you have a new suggested connection to review - LinkedIn (messages-noreply@linkedin.com) - 2020-06-29 0306.eml\n",
      "Everyone seems to want to study machine learning or be a data scientist. Are we headi...  - Quora Digest (digest-noreply@quora.com) - 2020-06-22 1058.eml\n",
      "Fast Forward to resilient business operations - 'Microsoft Singapore' (Microsoft@e-mail.microsoft.com) - 2020-07-03 1002.eml\n",
      "Get more out of your PDF - 'Adobe' (demand@mail.adobe.com) - 2020-06-22 1428.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-20 1658.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-21 0230.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-21 2022.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-22 0245.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-22 0708.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-22 1929.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-23 2041.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-24 2254.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-25 2154.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-26 0349.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-26 2326.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-27 0614.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-27 2344.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-30 0029.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-06-30 0911.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-07-01 0150.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-07-01 0844.eml\n",
      "hashinshin is live  THE BEST LOOKING STREAMER EVER LIVE NOW! - Twitch (no-reply@twitch.tv) - 2020-07-02 0307.eml\n",
      "Hays is looking for  Cyber Security Roles in Singapore. - LinkedIn (jobs-listings@linkedin.com) - 2020-07-02 0222.eml\n",
      "Honey-Mustard Coleslaw, Parmesan-Crusted Asparagus, Grilled Carrots with Cilantro-Yogurt Sauce... - 'Cook's Illustrated' (News@email.americastestkitchen.com) - 2020-06-28 2206.eml\n",
      "Hot Dogs & Hacking is live! Come hack our Shred cyber range - Security Innovation (getsecure@securityinnovation.com) - 2020-07-02 2004.eml\n",
      "How much do university professors earn on average  - Quora Digest (digest-noreply@quora.com) - 2020-06-29 1045.eml\n",
      "I have a B.S. in computer science but zero experience. What should I do to become ext...  - Quora Digest (digest-noreply@quora.com) - 2020-06-30 2317.eml\n",
      "I think I found proof that P = NP but I have no mathematical knowledge and don't know...  - Quora Digest (digest-noreply@quora.com) - 2020-06-23 2336.eml\n",
      "In a Pickle - 'Notes from the Test Kitchen' (News@email.americastestkitchen.com) - 2020-06-26 1809.eml\n",
      "In the Kitchen with Jack  Getting better, staying true. - 'America's Test Kitchen' (News@email.americastestkitchen.com) - 2020-06-24 1910.eml\n",
      "Introducing Hot Dogs & Hacking 2020 - a free CMD+CTRL event - Security Innovation (getsecure@securityinnovation.com) - 2020-06-23 0549.eml\n",
      "Is it worth moving away from machine learning and data science  - Quora Digest (digest-noreply@quora.com) - 2020-06-27 1501.eml\n",
      "Jun Wei Lim endorsed you for 1 skill - LinkedIn (notifications-noreply@linkedin.com) - 2020-06-22 0754.eml\n",
      "Keep it professional - 'Adobe' (demand@mail.adobe.com) - 2020-06-25 1002.eml\n",
      "Land Transport Authority (LTA) Singapore is looking for  Assistant Software Engineer. - LinkedIn (jobs-listings@linkedin.com) - 2020-06-23 0515.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-20 1531.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-21 1530.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-24 1531.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-25 1532.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-26 1532.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-27 1531.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-28 1531.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-07-01 1534.eml\n",
      "lck just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-07-02 1531.eml\n",
      "Learn the fundamentals of cloud computing with Azure Fundamentals on 7 & 8 July - 'Microsoft Singapore' (Microsoft@e-mail.microsoft.com) - 2020-06-23 1651.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-20 1750.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-21 0806.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-21 2223.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-22 2322.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-26 2224.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-27 1142.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-27 1815.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-28 0127.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-28 0826.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-28 2156.eml\n",
      "lec just went live on Twitch - Twitch (no-reply@twitch.tv) - 2020-06-29 2321.eml\n",
      "LIVE NOW - Creators from Asia Pacific - 'Adobe Live on Behance' (demand@mail.adobe.com) - 2020-06-24 0758.eml\n",
      "LIVE NOW - Creators from Asia Pacific - 'Adobe' (demand@mail.adobe.com) - 2020-07-01 0739.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-20 1557.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-21 1558.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-22 1549.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-23 1557.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-24 1554.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-25 1606.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-26 1606.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-26 2246.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-27 1555.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-28 1601.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-29 1553.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-06-30 1556.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-07-01 1553.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-07-02 1557.eml\n",
      "LPL is live  Our LPL English team is back! schedule take a look here  https _twitter.com_lplenglish_status_1239431776419729415 - Twitch (no-reply@twitch.tv) - 2020-07-02 2121.eml\n",
      "Make art from the comfort of your couch - 'Adobe' (demand@mail.adobe.com) - 2020-06-27 1651.eml\n",
      "Microsoft Tech News - Watch a demo of the Power Platform admin center - 'Microsoft' (Microsoft@e-mail.microsoft.com) - 2020-07-02 0849.eml\n",
      "Mix & muddle, stir & shake. Cocktail culture comes home. - 'America's Test Kitchen' (News@email.americastestkitchen.com) - 2020-07-02 1906.eml\n",
      "More info about Saturday's CMD+CTRL Cyber Range event - Security Innovation (getsecure@securityinnovation.com) - 2020-06-26 1001.eml\n",
      "More related to 'How do you insert an image in Javascript ' - Quora (curiosity-noreply@quora.com) - 2020-07-01 0232.eml\n",
      "More Sale More Smiles â€“ - 'Designer Outlet Parndorf' (DesignerOutletParndorf@mail.mcarthurglen.com) - 2020-06-23 1413.eml\n",
      "My daughter keeps on asking me to get her Netflix. I canâ€™t afford to pay for it every...  - Quora Digest (digest-noreply@quora.com) - 2020-06-25 1940.eml\n",
      "New Anime on MyAnimeList.net  Super Senko-san Time Episode 12 - 'MyAnimeList.net' (no-reply@myanimelist.net) - 2020-06-29 1542.eml\n",
      "New Normal, New Tools. Introduction to the new Surface Go2 and Surface Book 3. - 'Microsoft Singapore' (Microsoft@e-mail.microsoft.com) - 2020-06-29 1001.eml\n",
      "Nik Collection 3 By DxO  Our offer ends in a few hours! - Nik Collection Team (noreply@dxo.com) - 2020-06-30 2332.eml\n",
      "Nova Grappler on Cardfight!! Vanguard Wiki has been edited by Kind-Hearted-One - FANDOM (community@fandom.com) - 2020-06-22 1925.eml\n",
      "Our journalism. Your terms. Free for 30 days. - 'The Telegraph' (thetelegraph@email3.telegraph.co.uk) - 2020-06-28 1936.eml\n",
      "People are talking about Transcendence Dragon, Dragonic Nouvelle Vague on Cardfight!! Vanguard Wiki! - FANDOM (community@fandom.com) - 2020-06-25 0058.eml\n",
      "Perfect porch sitting activity! Read a free issue of Cook's... - 'America's Test Kitchen' (News@email.americastestkitchen.com) - 2020-06-27 2216.eml\n",
      "Procter & Gamble is looking for  Data Science - P&G Accelerate Internship (6 months). - LinkedIn (jobs-listings@linkedin.com) - 2020-06-30 0405.eml\n",
      "Revealed  the first countries to get UK air bridges - 'Telegraph Editor' (telegrapheditor@email3.telegraph.co.uk) - 2020-06-26 0059.eml\n",
      "Revealed  the guidelines for reopening schools - 'Telegraph Editor' (telegrapheditor@email3.telegraph.co.uk) - 2020-07-03 0031.eml\n",
      "See what's new with your favorite communities this week - FANDOM (community@fandom.com) - 2020-06-21 0831.eml\n",
      "See what's new with your favorite communities this week - FANDOM (community@fandom.com) - 2020-06-28 0836.eml\n",
      "Spike Brothers on Cardfight!! Vanguard Wiki has been edited by Xophix - FANDOM (community@fandom.com) - 2020-07-02 0105.eml\n",
      "Thank you, First Responders - 'Target' (reply@targetnewsletter.com.au) - 2020-06-22 1711.eml\n",
      "The answer to your vegetable woes  Vegetables Illustrated. - 'Cook's Illustrated' (News@email.americastestkitchen.com) - 2020-06-25 1906.eml\n",
      "The best of life beyond lockdown - free for 30 days - 'The Telegraph' (thetelegraph@email3.telegraph.co.uk) - 2020-07-01 1752.eml\n",
      "The man who turned on the President - 'Telegraph Editor' (telegrapheditor@email3.telegraph.co.uk) - 2020-06-23 0029.eml\n",
      "The Steam Summer Sale has begun - 'Steam' (noreply@steampowered.com) - 2020-06-27 0746.eml\n",
      "The tiniest croissant youâ€™ll ever meet. - Team ChefSteps (no-reply@chefsteps.com) - 2020-06-26 0843.eml\n",
      "The Well-Equipped Cook  Grilling Gear 101 - 'America's Test Kitchen' (News@email.americastestkitchen.com) - 2020-07-02 0004.eml\n",
      "The Well-Equipped Cook  Our Favorite Tools for One-Pot Cooking - Cookâ€™s Illustrated (News@email.americastestkitchen.com) - 2020-06-25 0007.eml\n",
      "There's still time! Get our Cook Like A Scientist box delivered to your door. - 'America's Test Kitchen' (News@email.americastestkitchen.com) - 2020-06-21 2206.eml\n",
      "Transaction Alerts - PayLah! Alerts (paylah.alert@dbs.com) - 2020-06-29 2206.eml\n",
      "Transaction Alerts - PayLah! Alerts (paylah.alert@dbs.com) - 2020-06-29 2208.eml\n",
      "Transaction Alerts - PayLah! Alerts (paylah.alert@dbs.com) - 2020-07-01 1941.eml\n",
      "Transaction Alerts - PayLah! Alerts (paylah.alert@dbs.com) - 2020-07-01 2014.eml\n",
      "Visit The Sounding Board Blog - WREN Home (hello@wrenhome.com) - 2020-06-25 2045.eml\n",
      "What the new lockdown rules mean for you - 'The Telegraph' (thetelegraph@email3.telegraph.co.uk) - 2020-06-24 0617.eml\n",
      "What will you grill  - Team ChefSteps (no-reply@chefsteps.com) - 2020-06-29 0048.eml\n",
      "Wish your Instant Pot could lighten up  - 'America's Test Kitchen' (News@email.americastestkitchen.com) - 2020-06-20 2207.eml\n",
      "You have an invitation from LingoAce - 'Facebook' (notification@facebookmail.com) - 2020-07-01 0226.eml\n",
      "â€œA crazy deal on BOTH magazines! â€ Yes. - 'Cook's Illustrated' (News@email.americastestkitchen.com) - 2020-06-30 1906.eml\n",
      "â¤ï¸ BTC, DOGE and ETH Rewards DOUBLED - RollerCoin Team (support@rollercoin.com) - 2020-07-03 0535.eml\n",
      "ðŸ‘®â€Somebody wants to empty your wallets. Watch outðŸ‘€ - RollerCoin Team (support@rollercoin.com) - 2020-06-27 0734.eml\n",
      "ðŸ’»Â See DxO PhotoLab 3 and the Nik Collection 3 By DxO in action - DxO Team (noreply@dxo.com) - 2020-07-03 0036.eml\n",
      "ðŸ˜±Â Nik Collection 3 By DxO  Our offer ends in 24 hours! - Nik Collection Team (noreply@dxo.com) - 2020-06-30 0207.eml\n"
     ]
    }
   ],
   "source": [
    "for x in phishing_2016:\n",
    "    print(\"{}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction (Body, Email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def ExtractEmail(filename):\n",
    "    fp = open(filename, 'rb')\n",
    "    mail = fp.read()\n",
    "    msg = email.message_from_bytes(mail)\n",
    "    fp.close()\n",
    "    return msg\n",
    "    \n",
    "def EmailParser(filename):\n",
    "    fp = open(filename, 'rb')\n",
    "    headers = BytesParser(policy=default).parse(fp)\n",
    "    fp.close()\n",
    "    return headers\n",
    "\n",
    "def ExtractBody(msg):\n",
    "    content = \"\"\n",
    "    if msg.is_multipart():\n",
    "        for payload in msg.get_payload():\n",
    "            content += str(payload.get_payload())\n",
    "    else:\n",
    "        content += str(msg.get_payload())\n",
    "    return content\n",
    "\n",
    "def CheckAttachment(msg):\n",
    "    attachment = 0\n",
    "    for part in msg.walk():\n",
    "        if part.get_content_maintype() == 'multipart':\n",
    "            continue\n",
    "        if part.get('Content-Disposition') is None:\n",
    "            continue\n",
    "    fileName = part.get_filename()\n",
    "    if bool(fileName):\n",
    "        attachment = 1\n",
    "    return attachment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpamScore(filename):\n",
    "    #print(\"{}\".format(filename))\n",
    "    spamScore = 0\n",
    "    try:\n",
    "        with open(filename,\"rb\") as f:      \n",
    "            assassin = SpamAssassin(f.read())\n",
    "            spamScore = assassin.get_score()\n",
    "        print(\"The spam score is {}\".format(spamScore))\n",
    "    except:\n",
    "        spamScore = 0\n",
    "        print(filename)\n",
    "    return spamScore\n",
    "\n",
    "def checkSpam(filename):\n",
    "    spamCheck = 0\n",
    "    with open(filename,\"rb\") as f:            \n",
    "        assassin = SpamAssassin(f.read())\n",
    "        spamCheck = assassin.is_spam()\n",
    "    print(\"it is a {}\".format(spamCheck))\n",
    "    return spamCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSenderReplyDiff(header):\n",
    "    senderReplyDiff = 1\n",
    "    try:\n",
    "        if header['from'] == header['to']:\n",
    "            senderReplyDiff = 0\n",
    "    except:\n",
    "        senderReplyDiff = 1\n",
    "    return senderReplyDiff\n",
    "\n",
    "def subj_reply(header):\n",
    "    try:\n",
    "        subj_reply = header['subject'].lower().startswith(\"re:\")\n",
    "    except:\n",
    "        subj_reply = \"\"\n",
    "    return subj_reply\n",
    "\n",
    "def subj_forward(header):\n",
    "    try:\n",
    "        subj_forward = header['subject'].lower().startswith(\"fwd:\")\n",
    "    except:\n",
    "        subj_forward = \"\"\n",
    "    return subj_forward\n",
    "\n",
    "def subj_noOfWords(header):\n",
    "    try:\n",
    "        subj_noOfWords = len(header['subject'].split())\n",
    "    except:\n",
    "        subj_noOfWords = 0\n",
    "    return subj_noOfWords\n",
    "\n",
    "def subj_noOfChar(header):\n",
    "    try:\n",
    "        subj_noOfChar = len(header['subject'])\n",
    "    except:\n",
    "        subj_noOfChar = 0\n",
    "    return subj_noOfChar\n",
    "\n",
    "def subj_verify(header):\n",
    "    try:\n",
    "        subj_verify = \"verify\" in header['subject'].lower()\n",
    "    except:\n",
    "        subj_verify = \"\"\n",
    "    return subj_verify\n",
    "\n",
    "def subj_debit(header):\n",
    "    try:\n",
    "        subj_debit = \"debit\" in header['subject'].lower()\n",
    "    except:\n",
    "        subj_debit = \"\"\n",
    "    return subj_debit\n",
    "\n",
    "def subj_bank(header):\n",
    "    try:\n",
    "        subj_bank = \"bank\" in header['subject'].lower()\n",
    "    except:\n",
    "        subj_bank = \"\"\n",
    "    return subj_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is 1.3\n",
      "The spam score is -0.6\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -0.9\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -0.4\n",
      "The spam score is -0.4\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -0.9\n",
      "The spam score is -5.9\n",
      "The spam score is 0.1\n",
      "The spam score is -1.7\n",
      "The spam score is -0.9\n",
      "The spam score is -0.9\n",
      "The spam score is -1.1\n",
      "The spam score is -1.7\n",
      "The spam score is -1.4\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -0.9\n",
      "The spam score is -1.3\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -0.9\n",
      "The spam score is -2.0\n",
      "The spam score is -0.9\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.7\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -2.0\n",
      "The spam score is -2.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -1.0\n",
      "The spam score is -2.0\n",
      "The spam score is -1.7\n",
      "The spam score is 1.4\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.0\n",
      "The spam score is -1.7\n",
      "The spam score is -1.0\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is 1.3\n",
      "The spam score is -0.9\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.3\n",
      "The spam score is -1.1\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is -1.1\n",
      "The spam score is -0.2\n",
      "The spam score is 1.3\n",
      "The spam score is 1.0\n",
      "The spam score is 1.0\n",
      "The spam score is 1.0\n",
      "The spam score is 1.0\n",
      "The spam score is -0.3\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n",
      "The spam score is 1.3\n",
      "The spam score is -0.9\n",
      "The spam score is -0.1\n",
      "The spam score is -0.5\n",
      "The spam score is 1.6\n",
      "The spam score is -1.7\n",
      "The spam score is -1.7\n"
     ]
    }
   ],
   "source": [
    "emails = []\n",
    "header = []\n",
    "spamScore = []\n",
    "#spamCheck = []\n",
    "#sender_emails = []\n",
    "#receiver_emails = []\n",
    "subject = []\n",
    "SenderReplyDiff = []\n",
    "subjReply = []\n",
    "subjForward = []\n",
    "subjNoOfWords = []\n",
    "subjNoOfChar = []\n",
    "subjVerify = []\n",
    "subjDebit = []\n",
    "subjBank = []\n",
    "\n",
    "for filename in phishing_2016:\n",
    "    emails.append(ExtractEmail(filename))\n",
    "    header = EmailParser(filename)\n",
    "    spamScore.append(SpamScore(filename))\n",
    "    #spamCheck.append(checkSpam(filename))\n",
    "    #sender_emails.append(header['from'])\n",
    "    #receiver_emails.append(header['to'])\n",
    "    subject.append(header['subject'])\n",
    "    SenderReplyDiff.append(checkSenderReplyDiff(header))\n",
    "    subjReply.append(subj_reply(header))\n",
    "    subjForward.append(subj_forward(header))\n",
    "    subjNoOfWords.append(subj_noOfWords(header))\n",
    "    subjNoOfChar.append(subj_noOfChar(header))\n",
    "    subjVerify.append(subj_verify(header))\n",
    "    subjDebit.append(subj_debit(header))\n",
    "    subjBank.append(subj_bank(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "body_contents = []\n",
    "checkAttachments = []\n",
    "\n",
    "for email in emails:\n",
    "    body_contents.append(ExtractBody(email))\n",
    "    checkAttachments.append(CheckAttachment(email))\n",
    "    #out.println(\"{}\".format(email))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScriptCheck(body_content):\n",
    "    script_scripts = False\n",
    "    try:\n",
    "        yikes = 0\n",
    "        soup = BeautifulSoup(body_content,'lxml')\n",
    "        script  = soup.find_all('script')\n",
    "        if len(script) > 0:\n",
    "            script_scripts = True\n",
    "    except:\n",
    "        script_scripts = False\n",
    "    return script_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check_popups(body_content):\n",
    "    script_popups = 0\n",
    "    if ScriptCheck(body_content):\n",
    "        soup = BeautifulSoup(body_content)\n",
    "        for script in soup.find_all('script'):\n",
    "            if \"window.open\" in str(script.contents):\n",
    "                script_popups = 1\n",
    "    return script_popups\n",
    "\n",
    "def check_javascript(body_content):\n",
    "    script_javascript = 0\n",
    "    if ScriptCheck(body_content):\n",
    "        soup = BeautifulSoup(body_content)\n",
    "        for script in soup.find_all('script'):\n",
    "            if script.get('type') is not None:\n",
    "                if \"text/javascript\" in script.get('type'):\n",
    "                    script_javascript = 1\n",
    "    return script_javascript\n",
    "\n",
    "def noOfOnClickEvents(body_content):\n",
    "    noOnClick = 0\n",
    "    if ScriptCheck(body_content):\n",
    "        soup = BeautifulSoup(body_content)\n",
    "        codes = soup.find_all('button',{\"onclick\":True})\n",
    "        noOnClick = len(codes)\n",
    "    return noOnClick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "script_exist = []\n",
    "checkPopup = []\n",
    "checkJS = []\n",
    "NoOnClick = []\n",
    "\n",
    "for body in body_contents:\n",
    "    script_exist.append(ScriptCheck(body))\n",
    "    checkPopup.append(check_popups(body))\n",
    "    checkJS.append(check_javascript(body))\n",
    "    NoOnClick.append(noOfOnClickEvents(body))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for HTML, Forms, Phishing Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HTMLCheck(body_content):\n",
    "    body_html = bool(BeautifulSoup(body_content, \"lxml\").find())\n",
    "    return body_html\n",
    "\n",
    "def FormCheck(body_content):\n",
    "    body_forms = bool(BeautifulSoup(body_content, \"lxml\").find(\"form\"))\n",
    "    return body_forms\n",
    "\n",
    "def checkFunctionWords(body_content):\n",
    "    body_noFunctionWords = 0\n",
    "    wordlist = re.sub(\"[^A-Za-z]\", \" \", body_content.strip()).lower().split()\n",
    "    function_words = [\"account\", \"access\", \"bank\", \"credit\", \"click\", \"identity\", \"inconvenience\", \"information\", \"limited\", \n",
    "                      \"log\", \"minutes\", \"password\", \"recently\", \"risk\", \"social\", \"security\", \"service\", \"suspended\", \"deactivate\"]\n",
    "    for word in function_words:\n",
    "        body_noFunctionWords += wordlist.count(word)\n",
    "    return body_noFunctionWords\n",
    "\n",
    "def checkNoWords(body_content):\n",
    "    body_NoWords = len(body_content.split())\n",
    "    return body_NoWords\n",
    "\n",
    "def checkNoChars(body_content):\n",
    "    body_NoChars = len(body_content) - body_content.count(' ') - body_content.count('\\n')\n",
    "    return body_NoChars\n",
    "\n",
    "def checkRichness(noWords, noChars):\n",
    "    body_richness = 0\n",
    "    try:\n",
    "        body_richness = noWords/noChars\n",
    "    except:\n",
    "        body_richness = 0\n",
    "    return body_richness\n",
    "\n",
    "def checkSuspension(body_content):\n",
    "    body_suspension = \"suspension\" in body_content.lower()\n",
    "    return body_suspension\n",
    "\n",
    "def checkVerifyAcc(body_content):\n",
    "    phrase = \"verifyyouraccount\"\n",
    "    content = re.sub(r\"[^A-Za-z]\", \"\", body_content.strip()).lower()\n",
    "    body_verifyYourAccount = phrase in content\n",
    "    return body_verifyYourAccount\n",
    "\n",
    "def checkDear(body_content):\n",
    "    body_dear = \"dear\" in body_content.lower()\n",
    "    return body_dear\n",
    "\n",
    "def uniqueWords(body_content):\n",
    "    words = set(body_content)\n",
    "    count = len(words)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_exist = []\n",
    "form_exist = []\n",
    "noFunctionWords = []\n",
    "noWords = []\n",
    "noChars = []\n",
    "check_suspend = []\n",
    "check_verify = []\n",
    "check_dear = []\n",
    "unique_Words = []\n",
    "\n",
    "for body in body_contents:\n",
    "    html_exist.append(HTMLCheck(str(body)))\n",
    "    form_exist.append(FormCheck(str(body)))\n",
    "    noFunctionWords.append(checkFunctionWords(str(body)))\n",
    "    noWords.append(checkNoWords(str(body)))\n",
    "    noChars.append(checkNoChars(str(body)))\n",
    "    check_suspend.append(checkSuspension(str(body)))\n",
    "    check_verify.append(checkVerifyAcc(str(body)))\n",
    "    check_dear.append(checkDear(str(body)))\n",
    "    unique_Words.append(uniqueWords(str(body)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Richness = []\n",
    "\n",
    "for x in range(0,len(noWords)):\n",
    "    Richness.append(checkRichness(noWords[x],noChars[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinks(body_content):\n",
    "    links = []\n",
    "    content = []\n",
    "    soup = BeautifulSoup(body_content, \"lxml\")\n",
    "    for link in soup.findAll('a'):\n",
    "        links.append(link.get(\"href\"))\n",
    "        content.append(link.text)\n",
    "    return links, content\n",
    "    \n",
    "def getURLs(body_content):\n",
    "    urls = re.findall(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", body_content)\n",
    "    return urls\n",
    "\n",
    "def get_domain(url):\n",
    "    domain = None\n",
    "    if url:\n",
    "        if u'@' not in str(url):\n",
    "            parsed_uri = urlparse(url)\n",
    "            domain = '{uri.netloc}'.format(uri=parsed_uri)\n",
    "            if domain.startswith(\"www.\"):\n",
    "                return domain[4:]\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ipaddr(links):\n",
    "    no_ipaddr = 1\n",
    "    ip_addr = []\n",
    "    for link in links:\n",
    "        link_address = get_domain(link)\n",
    "        if \":\" in str(link_address):\n",
    "            link_address = link_address[:link_address.index(\":\")]\n",
    "        try:\n",
    "            IP(link_address)\n",
    "            no_ipaddr = 0\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "    return no_ipaddr\n",
    "\n",
    "def check_atsym(links):\n",
    "    no_atsym = 1\n",
    "    ip_addr = []\n",
    "    for link in links:\n",
    "        if u'@' in str(link):\n",
    "            no_atsym = 0\n",
    "            break\n",
    "    return no_atsym\n",
    "\n",
    "def check_doubleslash(links):\n",
    "    no_doubleslash = 1\n",
    "    for link in links:\n",
    "        xd = str(link)[10:]\n",
    "        if u'//' in xd:\n",
    "            no_doubleslash = 0\n",
    "    return no_doubleslash\n",
    "\n",
    "def check_urlshorten(links):\n",
    "    no_urlshorten = 1\n",
    "    for link in links:\n",
    "        if u'bit.ly' in str(link):\n",
    "            no_urlshorten = 0\n",
    "        elif u'goo.gl' in str(link):\n",
    "            no_urlshorten = 0\n",
    "        elif u'tinyurl.com' in str(link):\n",
    "            no_urlshorten = 0\n",
    "        elif u'adf.ly' in str(link):\n",
    "            no_urlshorten = 0\n",
    "    return no_urlshorten\n",
    "\n",
    "def check_img(body_content):\n",
    "    soup = BeautifulSoup(body_content)\n",
    "    ImgLinks = soup.findAll('img')\n",
    "    noOfImgLinks = len(ImgLinks)\n",
    "    return noOfImgLinks\n",
    "\n",
    "def check_port(links):\n",
    "    no_diffport = 1\n",
    "    for link in links:\n",
    "        link_address = get_domain(link)\n",
    "        if \":\" in str(link_address):\n",
    "            port = link_address[link_address.index(\":\"):][1:]\n",
    "            if str(port) != str(80):\n",
    "                no_diffport = 0\n",
    "                break\n",
    "    return no_diffport\n",
    "\n",
    "def modalDomain(urls):\n",
    "    if urls:\n",
    "        modal_url = max(set(urls), key = urls.count)\n",
    "        return modal_url\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def check_NoOfDots(links):\n",
    "    noOfDots = 0\n",
    "    avg = 0\n",
    "    for link in links:\n",
    "        if link is not None:\n",
    "            noOfDots += link.count('.')\n",
    "    try:\n",
    "        avg = noOfDots/len(links)\n",
    "    except:\n",
    "        avg = 0\n",
    "    return avg\n",
    "        \n",
    "def avgDomainLength(links):\n",
    "    leng = 0\n",
    "    avgLen = 0\n",
    "    for link in links:\n",
    "        if link is not None:\n",
    "            leng += len(link)\n",
    "    try:\n",
    "        avgLen = leng/len(links)\n",
    "    except:\n",
    "        avgLen = 0\n",
    "    return avgLen\n",
    "\n",
    "def check_ContentURL(links,contents):\n",
    "    checkContentURL = 1\n",
    "    for x in range(0,len(contents)):\n",
    "        if validators.domain(contents[x]) == True:\n",
    "            if links[x] != contents[x]:\n",
    "                checkContentURL = 0\n",
    "    return checkContentURL\n",
    "\n",
    "def Whois (links):\n",
    "    checkWhois = 0\n",
    "    domain = ''\n",
    "    for link in links:\n",
    "        domain = get_domain(link)\n",
    "        try:\n",
    "            query = whois.query(domain)\n",
    "            date = query.creation_date\n",
    "            # CHECK IF DATE IF 60 DAYS OFEMAIL SENDING DATE AFTER CREATING WEBSITE\n",
    "        except:\n",
    "            continue\n",
    "    return checkWhois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noOfURLs = []\n",
    "noOfLinks = []\n",
    "\n",
    "for body in body_contents:\n",
    "    urls = getURLs(body)\n",
    "    noOfURLs.append(len(urls))\n",
    "    links, content = getLinks(body)\n",
    "    noOfLinks.append(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkIP = []\n",
    "checkAtSym = []\n",
    "checkdoubleslash = []\n",
    "checkURLShorten = []\n",
    "checkImg = []\n",
    "checkPort = []\n",
    "modalURL = []\n",
    "checkNoDots = []\n",
    "avg_DomainLength = []\n",
    "checkContentURL = []\n",
    "\n",
    "for body in body_contents:\n",
    "    links, content = getLinks(body)\n",
    "    urls = getURLs(body)\n",
    "    checkIP.append(check_ipaddr(links))\n",
    "    checkAtSym.append(check_atsym(links))\n",
    "    checkdoubleslash.append(check_doubleslash(links))\n",
    "    checkURLShorten.append(check_urlshorten(links))\n",
    "    checkImg.append(check_img(body))\n",
    "    checkPort.append(check_port(links))\n",
    "    modalURL.append(modalDomain(urls))\n",
    "    checkNoDots.append(check_NoOfDots(links))\n",
    "    avg_DomainLength.append(avgDomainLength(links))\n",
    "    checkContentURL.append(check_ContentURL(links, content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modal Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_domain(string):\n",
    "    domain = re.search(\"@[\\w.]+\", string)\n",
    "    if domain is None:\n",
    "        return None\n",
    "    return str(domain.group())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkModalDomainHeader (email_addr, modalURL):\n",
    "    send_domain = get_email_domain(email_addr)\n",
    "    modal_domain = get_domain(modalURL)\n",
    "    \n",
    "    send_nonModalSenderDomain = 0\n",
    "    if str(modalURL) != \"None\":\n",
    "        if send_domain != modal_domain:\n",
    "            send_nonModalSenderDomain = 1\n",
    "    return send_nonModalSenderDomain\n",
    "\n",
    "def checkHere(links, contents, modalURL):\n",
    "    checkHere = 1\n",
    "    for x in range(0,len(links)):\n",
    "        if contents[x] is not None:\n",
    "            if 'here' in contents[x].lower():\n",
    "                domain = get_domain(links[x])\n",
    "                if domain != 'here':\n",
    "                    checkHere = 0\n",
    "    return checkHere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkModal = []\n",
    "modalURLs = []\n",
    "\n",
    "for x in range(0,len(phishing_2016)):\n",
    "    modalURLs.append(modalURL[x])\n",
    "    header = EmailParser(filename)\n",
    "    checkModal.append(checkModalDomainHeader(header['from'],modalURL[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_Here = []\n",
    "\n",
    "for x in range(0,len(body_contents)):\n",
    "    links, contents = getLinks(body_contents[x])\n",
    "    check_Here.append(checkHere(links, contents, modalURLs[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMEMBER TO CHANGE TARGET NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'features_list = [\\'checkdoubleslash\\']\\n\\nos.chdir(\\'../../CSV\\')\\n\\nwith open(\\'phishing_dataset_6.csv\\',\\'w\\',newline=\\'\\') as result_file:\\n    writer = csv.writer(result_file)\\n    writer.writerow([\\'checkdoubleslash\\'])\\n    result_file.flush()\\n\\n    for x in range(0,len(emails)):\\n        print(\"{}\".format(x))\\n        writer.writerow([checkdoubleslash[x]])\\n        result_file.flush()'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''features_list = ['checkdoubleslash']\n",
    "\n",
    "os.chdir('../../CSV')\n",
    "\n",
    "with open('phishing_dataset_6.csv','w',newline='') as result_file:\n",
    "    writer = csv.writer(result_file)\n",
    "    writer.writerow(['checkdoubleslash'])\n",
    "    result_file.flush()\n",
    "\n",
    "    for x in range(0,len(emails)):\n",
    "        print(\"{}\".format(x))\n",
    "        writer.writerow([checkdoubleslash[x]])\n",
    "        result_file.flush()'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n"
     ]
    }
   ],
   "source": [
    "features_list = ['spamScore','SenderReplyDiff','checkAttachments','subjReply','subjForward','subjNoOfWords','subjNoOfChar','subjVerify','subjDebit',\n",
    "                 'subjBank','script_exist','checkPopup','checkJS','NoOnClick','html_exist','form_exist','noFunctionWords',\n",
    "                 'noWords','noChars','check_suspend','check_verify','check_dear','unique_Words','Richness','noOfURLs','noOfLinks','checkIP','checkAtSym','checkdoubleslash',\n",
    "                 'checkURLShorten','checkImg','checkPort','checkNoDots','avg_DomainLength','checkContentURL','checkModal','check_Here']\n",
    "\n",
    "os.chdir('../../CSV')\n",
    "\n",
    "with open('non_phishing_testing_37.csv','w',newline='') as result_file:\n",
    "    writer = csv.writer(result_file)\n",
    "    writer.writerow(['spamScore','SenderReplyDiff','checkAttachments','subjReply','subjForward','subjNoOfWords','subjNoOfChar','subjVerify','subjDebit',\n",
    "                 'subjBank','script_exist','checkPopup','checkJS','NoOnClick','html_exist','form_exist','noFunctionWords',\n",
    "                 'noWords','noChars','check_suspend','check_verify','check_dear','unique_Words','Richness','noOfURLs','noOfLinks','checkIP','checkAtSym','checkdoubleslash',\n",
    "                 'checkURLShorten','checkImg','checkPort','checkNoDots','avg_DomainLength','checkContentURL','checkModal','check_Here','Phishing',])\n",
    "    result_file.flush()\n",
    "\n",
    "    for x in range(0,len(emails)):\n",
    "        print(\"{}\".format(x))\n",
    "        \n",
    "        writer.writerow([spamScore[x],SenderReplyDiff[x],checkAttachments[x],subjReply[x],subjForward[x],subjNoOfWords[x],subjNoOfChar[x],subjVerify[x],subjDebit[x],\n",
    "                     subjBank[x],script_exist[x],checkPopup[x],checkJS[x],NoOnClick[x],html_exist[x],form_exist[x],noFunctionWords[x],\n",
    "                     noWords[x],noChars[x],check_suspend[x],check_verify[x],check_dear[x],unique_Words[x],Richness[x],noOfURLs[x],noOfLinks[x],checkIP[x],checkAtSym[x],checkdoubleslash[x],\n",
    "                     checkURLShorten[x],checkImg[x],checkPort[x],checkNoDots[x],avg_DomainLength[x],checkContentURL[x],checkModal[x],check_Here[x],'0',])\n",
    "        result_file.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
